{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea6c8a1b",
   "metadata": {},
   "source": [
    "# Day Two: Hyperparameter Tuning — Grid Search vs Random Search\n",
    "\n",
    "## Introduction\n",
    "\n",
    "When training machine learning models, it's often necessary to tune hyperparameters — these are configuration settings used to control the learning process. Unlike model parameters, hyperparameters are not learned from the data and must be set before training. \n",
    "\n",
    "Two commonly used strategies for hyperparameter tuning are **Grid Search** and **Random Search**. Both methods aim to find the best combination of hyperparameters that results in the highest model performance on validation data.\n",
    "\n",
    "---\n",
    "\n",
    "## What is Grid Search?\n",
    "\n",
    "Grid Search is a brute-force approach to hyperparameter tuning. It systematically tests every possible combination of hyperparameter values that the user defines in a grid.\n",
    "\n",
    "### How Grid Search Works:\n",
    "\n",
    "1. Define a set of values for each hyperparameter.\n",
    "2. Evaluate the model's performance using every possible combination from the grid.\n",
    "3. Choose the combination that performs best on the validation set.\n",
    "\n",
    "This method ensures that all specified combinations are tested, making it thorough but potentially time-consuming.\n",
    "\n",
    "### Example:\n",
    "\n",
    "Suppose you want to tune two hyperparameters:\n",
    "\n",
    "- `max_depth`: [3, 5, 10]\n",
    "- `min_samples_split`: [2, 4]\n",
    "\n",
    "Grid search will train the model on all 3 x 2 = 6 combinations of these hyperparameters.\n",
    "\n",
    "---\n",
    "\n",
    "## What is Random Search?\n",
    "\n",
    "Random Search offers a more efficient alternative. Instead of testing all possible combinations, it selects a fixed number of combinations randomly from the defined hyperparameter ranges.\n",
    "\n",
    "### How Random Search Works:\n",
    "\n",
    "1. Define a range or distribution for each hyperparameter.\n",
    "2. Randomly sample a fixed number of combinations.\n",
    "3. Train and evaluate the model for each sampled set of values.\n",
    "\n",
    "This approach allows for a broader search of the parameter space without the computational cost of evaluating every possibility.\n",
    "\n",
    "---\n",
    "# Grid search and Random Search Visualization\n",
    "![Clickhere](Gs&Rs.jpg)\n",
    "\n",
    "## Grid Search vs Random Search\n",
    "\n",
    "| Feature               | Grid Search                                     | Random Search                                  |\n",
    "|-----------------------|--------------------------------------------------|------------------------------------------------|\n",
    "| Search strategy        | Exhaustive — evaluates all combinations         | Random sampling of combinations                |\n",
    "| Computational cost     | High, especially with large parameter spaces    | Lower, scales better with more parameters      |\n",
    "| Coverage               | Limited to specified grid values                | Can explore unexpected but effective values    |\n",
    "| Best suited for        | Small search spaces with fewer parameters       | Large search spaces or when time is limited    |\n",
    "\n",
    "---\n",
    "\n",
    "## Practical Guidelines\n",
    "\n",
    "Choosing the right approach depends on your dataset, model complexity, and available computational resources.\n",
    "\n",
    "### General Tips:\n",
    "\n",
    "1. **Start broad with random search**:\n",
    "   Begin by exploring a wide range of values to find promising regions in the hyperparameter space.\n",
    "\n",
    "2. **Refine with grid search**:\n",
    "   After identifying the best-performing ranges using random search, apply grid search in a narrower region for fine-tuning.\n",
    "\n",
    "3. **Understand parameter sensitivity**:\n",
    "   - Some parameters like learning rate often require fine-grained tuning (e.g., 0.001, 0.01, 0.1).\n",
    "   - Others like number of estimators or depth can tolerate larger steps (e.g., 50, 100, 150).\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "Grid search and random search are both effective methods for hyperparameter tuning. \n",
    "\n",
    "- Use **grid search** when the search space is small and you want a thorough evaluation.\n",
    "- Use **random search** when the search space is large or when computational time is limited.\n",
    "- Combining both can yield optimal results: start wide with random search, then fine-tune with grid search.\n",
    "\n",
    "#### If I want to get deeper\n",
    "[BlogPost](https://www.sabrepc.com/blog/deep-learning-and-ai/grid-search-and-random-search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b95cbe3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Name: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Target Name: ['setosa' 'versicolor' 'virginica']\n",
      "Best Parameters (Grid Search): {'max_depth': None, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "GridSearch Accuracy Score: 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# load dataset\n",
    "data = load_iris()\n",
    "\n",
    "# features and target\n",
    "x,y = data.data, data.target\n",
    "\n",
    "# Split dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=7)\n",
    "\n",
    "print(f\"Features Name: {data.feature_names}\")\n",
    "print(f\"Target Name: {data.target_names}\")\n",
    "\n",
    "# define hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split':[2, 5, 10]\n",
    " }\n",
    "\n",
    "# Initilize Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "  estimator= RandomForestClassifier(random_state=7),\n",
    "  param_grid=param_grid,\n",
    "  cv=5,\n",
    "  scoring='accuracy',\n",
    "  n_jobs=-1,  \n",
    ")\n",
    "\n",
    "# perform grid search\n",
    "grid_search.fit(x_train,y_train)\n",
    "\n",
    "# Evaluate the parameters\n",
    "best_grid_model = grid_search.best_estimator_\n",
    "y_pred = best_grid_model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best Parameters (Grid Search): {grid_search.best_params_}\")\n",
    "print(f\"GridSearch Accuracy Score: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
